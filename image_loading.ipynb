{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga del dataset *Brain MRI Images for Brain Tumor Detection*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de empezar con el entrenamiento de los diferentes modelos de redes neuronales convolucionales, debemos asegurarnos de que los datos presentan un formato adecuado para ser utilizados como *input* de liberías como ``Keras`` o ``scikit-learn``. En concreto, si el proceso de entrenamiento se va a llevar a cabo con redes neuronales convolucionales (CNN) el *input* de dichas redes debe adoptar la forma de una matriz con dimensiones constantes. Dicho de otra forma, el proceso que llevemos a cabo en este cuaderno debe convertir todas las imágenes del conjunto de datos en matrices de las mismas dimensiones. En lo que respecta a nuestro trabajo, convertiremos todos nuestros *inputs* en imágenes de 224x224 píxeles. \n",
    "\n",
    "El primer paso para proceder con estas transformaciones, consistirá en realizar la carga de estas imágenes. Para ello, haremos uso del módulo ``os`` para recorrer los directorios que las contienen, así como el módulo ``matplotlib.pyplot`` y su función ``imread`` para leerlas y convertirlas en *arrays* de tipo ``numpy``. Una vez finalizado el proceso, las listas ``no_images`` y ``yes_images`` contendrán los arrays ``numpy`` que representan imágenes sin tejido canceroso y con tejido canceroso respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Reading files with positive diagnostic...\n",
      "[!] Positive files read!\n",
      "[!] Reading files with negative diagnostic...\n",
      "[!] Negative files read!\n"
     ]
    }
   ],
   "source": [
    "img_yes = '../data/yes/'\n",
    "img_no = '../data/no/'\n",
    "\n",
    "yes_files = os.listdir(img_yes)\n",
    "no_files = os.listdir(img_no)\n",
    "\n",
    "yes_images, no_images = [], []\n",
    "print('[!] Reading files with positive diagnostic...')\n",
    "for file in yes_files:\n",
    "    yes_images.append(plt.imread(f'{img_yes}{file}'))\n",
    "print('[!] Positive files read!')\n",
    "\n",
    "print('[!] Reading files with negative diagnostic...')\n",
    "for file in no_files:\n",
    "    no_images.append(plt.imread(f'{img_no}{file}'))\n",
    "print('[!] Negative files read!')\n",
    "\n",
    "all_images = yes_images + no_images\n",
    "YES_SIZE, NO_SIZE = len(yes_images), len(no_images)\n",
    "TOTAL_SIZE = len(all_images)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez realizada la carga de las imágenes, comenzaremos el procesamiento de las mismas en diferentes etapas. Por una parte, debemos prestar atención a cómo la función ``imread`` realiza la lectura de las imágenes. Como se ha explicado previamente, esta función lee la imágen y la transforma en un *array* de tipo ``numpy``. Sin embargo, en función de la naturaleza de la imágen los *arrays* obtenidos pueden tener diferentes dimensiones o diferente tipo (``dtype``). En este caso, distinguimos tres tipos de imágen:\n",
    "\n",
    "1. **Imágenes en escala de gris**: estas imágenes vienen representadas como arrays bidimensionales (matrices) cuyas dimensiones coinciden con las dimensiones de la imagen. Por ejemplo, si realizamos la carga de una imágen de 512x512 píxeles obtendremos una matriz de 512 filas y 512 columnas. Cada posición de este array será un número entero entre 0 y 255 que representa una tonalidad de gris. Este tipo de imágenes presenta la ventaja de que sus píxeles pueden representarse como enteros sin signo de 8 bits (``uint8`` en ``numpy``), por lo que disminuyen significativamente los requisitos de memoria.\n",
    "\n",
    "2. **Imágenes en escala RGB**: estas imágenes vienen representadas como arrays tridimensionales. Una forma de entender estas imágenes sería como un conjunto de tres matrices, cada una representando un color, teniendo en cuenta además que cada matriz tiene las mismas dimensiones que la propia imágen. Por ejemplo, si se realiza la carga de una imágen RGB de 512x512 píxeles, obtendríamos un array de dimensiones ``(512, 512, 3)``. De nuevo, cada elemento de este array será un número entero entre 0 y 255, por lo que podrá representarse como un entero sin signo de 8 bits.\n",
    "\n",
    "3. **Imágenes con formato ``.png``**: estas imágenes vienen representadas como arrays de cuatro dimensiones, es decir, son imágenes de tipo RGBA (las imágenes RGBA surgen de la combinación de imágenes RGB con un cuarto canal de tipo *alpha* que sirve para indicar el grado de opacidad de cada píxel). La principal diferencia con los formatos anteriores, es que cada elemento del *array* es un número real entre 0 y 1 y por tanto, se representan en memoria mediante números en coma flotante de 32 bits (``float32`` en ``numpy``).\n",
    "\n",
    "Para nuestro trabajo, utilizaremos como *input* imágenes en escala de gris de dimensiones 224x224 píxeles. Por tanto, el primer paso para procesar las imágenes consistirá en transformarlas a escala de gris. Para ello, se implementaron las siguientes funciones:\n",
    "\n",
    "- ``convert_to_int_matrix(img_list)``: esta función recibe como argumento una lista con imágenes en formato *array* y convierte a formato entero aquellas imágenes que presentan elementos en coma flotante. Como se ha explicado previamente, las imágenes en formato ``.png`` se representan mediante números reales entre 0 y 1. Para realizar dicha conversión, multiplicamos cada elemento por 255 (que es el entero más alto en escala de grises) y posteriormente forzamos la conversión a entero de todos los elementos mediante el método ``astype`` de ``numpy``, utilizando ``np.uint8`` para indicar la transformación a entero de 8 bits sin signo.\n",
    "\n",
    "- ``imgs_to_grayscale(img_list)``: esta función recibe como argumento una lista con imágenes en formato *array* y las convierte a imágenes en escala de gris. Para ello, se hace uso de la función ``cvtColor`` del módulo ``cv2`` (OpenCV2 para Python) con el código ``cv2.COLOR_BGR2GRAY`` como código de conversión. De esta forma, las imágenes se convierten a *arrays* bidimensionales que representan la imágen convertida a escala de grises.\n",
    "\n",
    "Al realizar estas llamadas en el orden expuesto, las imágenes pasarán a estar representadas en escala de gris (con todos sus elementos entre 0 y 255). Una vez realizadas estas primeras transformaciones, se puede proceder a la siguiente etapa del preprocesado que consistirá en la eliminación del ruido en las imágenes. La mayoría de imágenes de nuestro dataset objeto contienen espacios y áreas no deseadas (como anotaciones en las esquinas) que podrían provocar un rendimiento pobre de los clasificadores a entrenar. Por tanto, nuestro objetivo consistirá en la eliminación de estas regiones ruidosas utilizando algoritmos que nos permitan detectar el contorno de los cerebros. El procedimiento que proponemos es muy similar al que se expone en [este artículo](https://www.sciencedirect.com/science/article/pii/S2666827020300049?via%3Dihub) y se explica en más detalle a continuación:\n",
    "\n",
    "1. Conversión a imágenes binarias mediante *thresholding*: en primer lugar, se procedió con la binarización de las imágenes mediante la función  ``threshold`` del módulo ``cv2``. Esta operación consiste en seleccionar un valor de *threshold* y aplicarlo a cada píxel de la imágen. Si el píxel es menor que el valor de *threshold* su valor se fija a 0, en otro caso, su valor se fija a cierto valor máximo. En nuestro caso, fijamos a 30 el valor de threshold (``THRESH``) y a 255 el valor máximo (``MAX_VALUE``, que es el valor más alto que puede aparecer en la codificación de una imágen). De esta forma, lograremos una imágen en \"blanco y negro\", lo que facilitará el trabajo de los algoritmos de detección de contornos. \n",
    "\n",
    "2. Aplicación de operaciones de erosión y dilatación:\n",
    "\n",
    "3. Difuminado *gaussiano*: \n",
    "\n",
    "4. Detección de contornos y puntos extremos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESH = 30\n",
    "MAX_VALUE = 255\n",
    "\n",
    "def convert_to_int_matrix(img_list):\n",
    "    MIN, MAX = 0, 255\n",
    "    for i, img in enumerate(img_list):\n",
    "        if img.dtype == np.float32:\n",
    "            tmp = np.copy(img) * MAX\n",
    "            img_list[i] = tmp.astype(np.uint8)\n",
    "\n",
    "def resize_imgs(img_list, height, width):\n",
    "    for i, img in enumerate(img_list):\n",
    "        img_list[i] = cv2.resize(img, (height, width))\n",
    "\n",
    "def imgs_to_grayscale(img_list):\n",
    "    for i, img in enumerate(img_list):\n",
    "        if len(img.shape) == 3:\n",
    "            img_list[i] = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def gaussian_blur(img_list):\n",
    "    for i, img in enumerate(img_list):\n",
    "        img_list[i] = cv2.GaussianBlur(img, (5, 5), 0) \n",
    "\n",
    "def threshold_imgs(img_list):\n",
    "    for i, img in enumerate(img_list):\n",
    "        _, img_list[i] = cv2.threshold(img, THRESH, MAX_VALUE, cv2.THRESH_BINARY)\n",
    "\n",
    "def erode_imgs(img_list, iter=1):\n",
    "    for i, img in enumerate(img_list):\n",
    "        img_list[i] = cv2.erode(img, None, iterations=iter)\n",
    "\n",
    "def dilate_imgs(img_list, iter=1):\n",
    "    for i, img in enumerate(img_list):\n",
    "        img_list[i] = cv2.dilate(img, None, iterations=iter)\n",
    "\n",
    "def flatten_contour(contour_list):\n",
    "    tmp = contour_list[0]\n",
    "    shape = tmp.shape\n",
    "    aux = np.zeros(shape=(shape[0], shape[2]), dtype=int)\n",
    "    for i in range(shape[0]):\n",
    "        aux[i] = tmp[i].flatten()\n",
    "    return aux\n",
    "\n",
    "def find_extreme_points(contour_list):\n",
    "    col_1 = contour_list[:, 0]\n",
    "    col_0 = contour_list[:, 1]\n",
    "    x_left, x_right = np.argmin(col_0), np.argmax(col_0)\n",
    "    y_top, y_bot = np.argmax(col_1), np.argmin(col_1)\n",
    "    ret = np.zeros(shape=(4, 2), dtype=int)\n",
    "    ret[0, :], ret[1, :] = contour_list[x_left], contour_list[x_right]\n",
    "    ret[2, :], ret[3, :] = contour_list[y_top], contour_list[y_bot]\n",
    "    return ret  \n",
    "\n",
    "def get_contour(img_list_morph, img_list, mode):\n",
    "    extreme_points, i = [], 0\n",
    "    for img_morph, img in zip(img_list_morph, img_list):\n",
    "        cont, _ = cv2.findContours(image=img_morph, mode=mode, method=cv2.CHAIN_APPROX_NONE)\n",
    "        cont_flat = flatten_contour(cont)\n",
    "        extreme_points.append(find_extreme_points(cont_flat))\n",
    "        i+= 1\n",
    "        if i % 50 == 0: print(f'[!] {i} images processed...')\n",
    "        # print(extreme_points[-1])\n",
    "        img_copy = img.copy()\n",
    "        # print(f'img_shape: {img_copy.shape}')\n",
    "        # print(f'extreme_point: {extreme_points[-1]}')\n",
    "        # for i in range(4):\n",
    "        #     img_copy = cv2.circle(img_copy, extreme_points[-1][i, :], radius=5, color=(0, 255, 0), thickness=-1)\n",
    "        # cv2.imshow(\"Image\", img_copy)\n",
    "        # cv2.waitKey()\n",
    "        # cv2.drawContours(image=img_copy, contours=cont, contourIdx=-1, color=(0, 0, 255), thickness=4, lineType=cv2.LINE_AA)\n",
    "        # cv2.imshow(\"Image\", img_copy)\n",
    "        # cv2.waitKey()\n",
    "    print(f'[!] Total of {i} images processed!')\n",
    "    return np.array(extreme_points)  \n",
    "\n",
    "def draw_img(img_list, index):\n",
    "    if index < len(img_list):\n",
    "        cv2.imshow(\"Brain image\", img_list[index])\n",
    "        cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 240)\n",
      "(1080, 1920, 3)\n",
      "(664, 550, 4)\n",
      "(725, 728, 4)\n",
      "(512, 512, 4)\n",
      "(400, 393, 4)\n",
      "(400, 393, 4)\n",
      "(454, 442, 4)\n"
     ]
    }
   ],
   "source": [
    "INDEX = 0\n",
    "HEIGHT, WIDTH = 224, 224\n",
    "convert_to_int_matrix(all_images)\n",
    "all_images_morph = all_images.copy()\n",
    "draw_img(all_images_morph, INDEX)\n",
    "imgs_to_grayscale(all_images_morph)\n",
    "draw_img(all_images_morph, INDEX)  \n",
    "threshold_imgs(all_images_morph)\n",
    "draw_img(all_images_morph, INDEX)\n",
    "erode_imgs(all_images_morph, iter=2)\n",
    "draw_img(all_images_morph, INDEX)\n",
    "dilate_imgs(all_images_morph, iter=4)\n",
    "draw_img(all_images_morph, INDEX)\n",
    "gaussian_blur(all_images_morph)\n",
    "draw_img(all_images_morph, INDEX)\n",
    "cv2.destroyAllWindows()\n",
    "extreme_points = get_contour(all_images_morph, all_images, cv2.RETR_EXTERNAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_images(extreme_points, img_list):\n",
    "    new_images = []\n",
    "    for extreme_point, img in zip(extreme_points, img_list):\n",
    "        x_left, x_right = extreme_point[0, 1], extreme_point[1, 1]\n",
    "        y_top, y_bot = extreme_point[2, 0], extreme_point[3, 0]\n",
    "        size_h, size_v = x_right - x_left, y_top - y_bot\n",
    "        # print(f'img_shape: {img.shape}')\n",
    "        # print(f'x_left: {x_left} - x_right: {x_right} - y_top: {y_top} - y_bot: {y_bot}')\n",
    "        # tmp = np.zeros(shape=(size_h, size_v), dtype=np.uint8)\n",
    "        # tmp = img[x_left:x_right, y_bot:y_top].copy()\n",
    "        tmp = np.zeros(shape=(size_h, size_v), dtype=np.uint8)\n",
    "        for i, k in zip(range(x_left, x_right), range(size_h)):\n",
    "            for j, l in zip(range(y_bot, y_top), range(size_v)):\n",
    "                tmp[k, l] = img[i, j]\n",
    "        new_images.append(tmp)\n",
    "    return new_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grey_imgs = all_images.copy()\n",
    "imgs_to_grayscale(grey_imgs)\n",
    "new_images = cut_images(extreme_points, grey_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_images(img_morph_list, img_list):\n",
    "    correct_yes_images, correct_no_images = [], []\n",
    "    incorrect_yes_images, incorrect_no_images = [], []\n",
    "    for img_morph, img, i in zip(img_morph_list, img_list, range(len(img_list))):\n",
    "        cv2.imshow(\"Brain\", img_morph)\n",
    "        key = cv2.waitKey()\n",
    "        if key == 13:\n",
    "            if i < YES_SIZE:\n",
    "                correct_yes_images.append(img_morph)\n",
    "            else:\n",
    "                correct_no_images.append(img_morph)\n",
    "        elif key == 8:\n",
    "            if i < YES_SIZE:\n",
    "                incorrect_yes_images.append(img)\n",
    "            else:\n",
    "                incorrect_no_images.append(img)\n",
    "        if i % 50 == 0:\n",
    "            print(f'[!] {i} images checked...')\n",
    "    return correct_yes_images, correct_no_images, incorrect_yes_images, incorrect_no_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] 0 images checked...\n",
      "[!] 50 images checked...\n",
      "[!] 100 images checked...\n",
      "[!] 150 images checked...\n",
      "[!] 200 images checked...\n",
      "[!] 250 images checked...\n"
     ]
    }
   ],
   "source": [
    "correct_yes_images, correct_no_images, incorrect_yes_images, incorrect_no_images = check_images(new_images, grey_imgs)\n",
    "cv2.destroyAllWindows()\n",
    "resize_imgs(correct_yes_images, HEIGHT, WIDTH)\n",
    "resize_imgs(correct_no_images, HEIGHT, WIDTH)\n",
    "# correct_yes_images = np.load('./numpy_arrays/correct_yes_images.npy', allow_pickle=True)\n",
    "# correct_no_images = np.load('./numpy_arrays/correct_no_images.npy', allow_pickle=True)\n",
    "# incorrect_yes_images = np.load('./numpy_arrays/incorrect_yes_images.npy', allow_pickle=True)\n",
    "# incorrect_no_images = np.load('./numpy_arrays/incorrect_no_images.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] 203 correct images!\n",
      "[!] 50 incorrect images!\n"
     ]
    }
   ],
   "source": [
    "print(f'[!] {len(correct_yes_images) + len(correct_no_images)} correct images!')\n",
    "print(f'[!] {len(incorrect_yes_images) + len(incorrect_no_images)} incorrect images!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kmart\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    }
   ],
   "source": [
    "NP_PATH = './numpy_arrays'\n",
    "np.save(f'{NP_PATH}/correct_yes_images.npy', correct_yes_images, allow_pickle=True)\n",
    "np.save(f'{NP_PATH}/correct_no_images.npy', correct_no_images, allow_pickle=True)\n",
    "np.save(f'{NP_PATH}/incorrect_yes_images.npy', incorrect_yes_images, allow_pickle=True)\n",
    "np.save(f'{NP_PATH}/incorrect_no_images.npy', incorrect_no_images, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:180: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] 50 images processed...\n",
      "[!] Total of 50 images processed!\n",
      "[!] 0 images checked...\n",
      "[!] 17 correct images!\n",
      "[!] 33 incorrect images!\n"
     ]
    }
   ],
   "source": [
    "THRESH, INDEX = 20, 0\n",
    "YES_SIZE, NO_SIZE = len(incorrect_yes_images), len(incorrect_no_images)\n",
    "\n",
    "original_incorrect_images = np.concatenate((incorrect_yes_images, incorrect_no_images))\n",
    "all_incorrect_images = original_incorrect_images.copy()\n",
    "\n",
    "threshold_imgs(all_incorrect_images)\n",
    "erode_imgs(all_incorrect_images, iter=2)\n",
    "dilate_imgs(all_incorrect_images, iter=4)\n",
    "gaussian_blur(all_incorrect_images)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "extreme_points = get_contour(all_incorrect_images, original_incorrect_images, cv2.RETR_EXTERNAL)\n",
    "new_images = cut_images(extreme_points, original_incorrect_images)\n",
    "res_imgs = check_images(new_images, original_incorrect_images)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f'[!] {len(res_imgs[0]) + len(res_imgs[1])} correct images!')\n",
    "print(f'[!] {len(res_imgs[2]) + len(res_imgs[3])} incorrect images!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] 220 total correct images!\n",
      "[!] 33 total incorrect images!\n"
     ]
    }
   ],
   "source": [
    "resize_imgs(res_imgs[0], HEIGHT, WIDTH)\n",
    "resize_imgs(res_imgs[1], HEIGHT, WIDTH)\n",
    "res_correct_yes = np.concatenate((np.load(f'{NP_PATH}/correct_yes_images.npy'), np.array(res_imgs[0], dtype=np.uint8)))\n",
    "res_correct_no = np.concatenate((np.load(f'{NP_PATH}/correct_no_images.npy'), np.array(res_imgs[1], dtype=np.uint8)))\n",
    "print(f'[!] {len(res_correct_yes) + len(res_correct_no)} total correct images!')\n",
    "print(f'[!] {TOTAL_SIZE - (len(res_correct_yes)+len(res_correct_no))} total incorrect images!')\n",
    "np.save(f'{NP_PATH}/correct_yes_images_2.npy', res_correct_yes, allow_pickle=True)\n",
    "np.save(f'{NP_PATH}/correct_no_images_2.npy', res_correct_no, allow_pickle=True)\n",
    "np.save(f'{NP_PATH}/incorrect_yes_images_2.npy', res_imgs[2], allow_pickle=True)\n",
    "np.save(f'{NP_PATH}/incorrect_no_images_2.npy', res_imgs[3], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_yes = np.ones(shape=(len(res_correct_yes),), dtype=np.uint8)\n",
    "class_no = np.zeros(shape=(len(res_correct_no),), dtype=np.uint8)\n",
    "np.save(f'{NP_PATH}/classes.npy', np.concatenate((class_yes, class_no)), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134\n",
      "86\n"
     ]
    }
   ],
   "source": [
    "print(len(res_correct_yes))\n",
    "print(len(res_correct_no))\n",
    "for img in res_correct_yes:\n",
    "    cv2.imshow(\"yes\", img)\n",
    "    cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "for img in res_correct_no:\n",
    "    cv2.imshow(\"no\", img)\n",
    "    cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12749f567798517b8543354a13719bbd42e9e3e56a89ba27a040f4f72d5c2230"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
