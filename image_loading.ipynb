{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga del dataset *Brain MRI Images for Brain Tumor Detection*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de empezar con el entrenamiento de los diferentes modelos de redes neuronales convolucionales, debemos asegurarnos de que los datos presentan un formato adecuado para ser utilizados como *input* de liberías como ``Keras`` o ``scikit-learn``. En concreto, si el proceso de entrenamiento se va a llevar a cabo con redes neuronales convolucionales (CNN) el *input* de dichas redes debe adoptar la forma de una matriz con dimensiones constantes. Dicho de otra forma, el proceso que llevemos a cabo en este cuaderno debe convertir todas las imágenes del conjunto de datos en matrices de las mismas dimensiones. En lo que respecta a nuestro trabajo, convertiremos todos nuestros *inputs* en imágenes de 224x224 píxeles. \n",
    "\n",
    "El primer paso para proceder con estas transformaciones, consistirá en realizar la carga de estas imágenes. Para ello, haremos uso del módulo ``os`` para recorrer los directorios que las contienen, así como el módulo ``matplotlib.pyplot`` y su función ``imread`` para leerlas y convertirlas en *arrays* de tipo ``numpy``. Una vez finalizado el proceso, las listas ``no_images`` y ``yes_images`` contendrán los arrays ``numpy`` que representan imágenes sin tejido canceroso y con tejido canceroso respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Reading files with positive diagnostic...\n",
      "(218, 180, 3)\n",
      "(360, 319)\n",
      "(348, 287, 3)\n",
      "(336, 300)\n",
      "(630, 587, 3)\n",
      "(993, 825, 3)\n",
      "(890, 700, 3)\n",
      "(246, 205, 3)\n",
      "(253, 200, 3)\n",
      "(512, 512, 3)\n",
      "(1200, 1059, 3)\n",
      "(279, 258, 3)\n",
      "(369, 400, 3)\n",
      "(324, 272, 3)\n",
      "(366, 310, 3)\n",
      "(312, 254, 3)\n",
      "(249, 178, 3)\n",
      "(298, 260, 3)\n",
      "(269, 249, 3)\n",
      "(310, 246, 3)\n",
      "(500, 377)\n",
      "(245, 224, 3)\n",
      "(325, 254, 3)\n",
      "(300, 289)\n",
      "(355, 311, 3)\n",
      "(352, 321, 3)\n",
      "(283, 231, 3)\n",
      "(380, 310, 3)\n",
      "(359, 300, 3)\n",
      "(431, 400, 3)\n",
      "(355, 310, 3)\n",
      "(370, 286, 3)\n",
      "(309, 232, 3)\n",
      "(334, 283, 3)\n",
      "(354, 303, 3)\n",
      "(360, 313, 3)\n",
      "(348, 297, 3)\n",
      "(351, 273, 3)\n",
      "(1200, 1059, 3)\n",
      "(316, 270, 3)\n",
      "(336, 264, 3)\n",
      "(303, 223, 3)\n",
      "(291, 253, 3)\n",
      "(350, 272, 3)\n",
      "(300, 263, 3)\n",
      "(325, 254, 3)\n",
      "(300, 289)\n",
      "(355, 290, 3)\n",
      "(354, 279, 3)\n",
      "(586, 467, 3)\n",
      "(380, 310, 3)\n",
      "(318, 273, 3)\n",
      "(347, 300, 3)\n",
      "(173, 189, 3)\n",
      "(380, 318, 3)\n",
      "(450, 355, 3)\n",
      "(244, 206, 3)\n",
      "(879, 766, 3)\n",
      "(359, 297, 3)\n",
      "(342, 273, 3)\n",
      "(351, 262, 3)\n",
      "(256, 256, 3)\n",
      "(340, 314, 3)\n",
      "(212, 209, 3)\n",
      "(300, 240, 3)\n",
      "(247, 204, 3)\n",
      "(380, 294, 3)\n",
      "(277, 272, 3)\n",
      "(1024, 1024)\n",
      "(344, 279, 3)\n",
      "(331, 272, 3)\n",
      "(351, 278, 3)\n",
      "(237, 213, 3)\n",
      "(355, 294, 3)\n",
      "(338, 248, 3)\n",
      "(315, 289, 3)\n",
      "(331, 260, 3)\n",
      "(630, 504, 3)\n",
      "(236, 213, 3)\n",
      "(349, 278, 3)\n",
      "(256, 197, 3)\n",
      "(338, 283, 3)\n",
      "(251, 201, 3)\n",
      "(295, 283, 3)\n",
      "(352, 281, 3)\n",
      "(960, 781, 3)\n",
      "(349, 292, 3)\n",
      "(324, 278, 3)\n",
      "(630, 628, 3)\n",
      "(630, 630, 3)\n",
      "(630, 630, 3)\n",
      "(630, 630, 3)\n",
      "(519, 456, 3)\n",
      "(325, 300)\n",
      "(294, 250)\n",
      "(555, 526, 3)\n",
      "(512, 512, 3)\n",
      "(380, 310, 3)\n",
      "(446, 450, 3)\n",
      "(251, 204, 3)\n",
      "(360, 319)\n",
      "(325, 300)\n",
      "(278, 236)\n",
      "(225, 225, 3)\n",
      "(365, 306, 3)\n",
      "(1427, 1275)\n",
      "(210, 200, 3)\n",
      "(337, 293, 3)\n",
      "(340, 291, 3)\n",
      "(929, 634, 3)\n",
      "(355, 320, 3)\n",
      "(307, 271, 3)\n",
      "(350, 315, 3)\n",
      "(938, 911, 3)\n",
      "(938, 911)\n",
      "(219, 230, 3)\n",
      "(325, 300)\n",
      "(620, 620, 3)\n",
      "(239, 211, 3)\n",
      "(340, 314, 3)\n",
      "(270, 229, 3)\n",
      "(938, 911, 3)\n",
      "(255, 197, 3)\n",
      "(520, 433, 3)\n",
      "(294, 250)\n",
      "(243, 205, 3)\n",
      "(340, 288, 3)\n",
      "(233, 215, 3)\n",
      "(630, 504, 3)\n",
      "(456, 374, 3)\n",
      "(325, 300)\n",
      "(349, 300, 3)\n",
      "(290, 250, 3)\n",
      "(620, 620, 3)\n",
      "(338, 264, 3)\n",
      "(442, 353, 3)\n",
      "(353, 300, 3)\n",
      "(251, 201, 3)\n",
      "(431, 400, 3)\n",
      "(446, 450, 3)\n",
      "(234, 216, 3)\n",
      "(223, 226, 3)\n",
      "(308, 244, 3)\n",
      "(350, 272, 3)\n",
      "(286, 241, 3)\n",
      "(630, 630, 3)\n",
      "(512, 512, 3)\n",
      "(1280, 1061, 3)\n",
      "(260, 194, 3)\n",
      "(300, 240)\n",
      "(225, 225, 3)\n",
      "(938, 864, 3)\n",
      "(355, 272, 3)\n",
      "(323, 276, 3)\n",
      "(357, 283, 3)\n",
      "[!] Positive files read!\n",
      "[!] Reading files with negative diagnostic...\n",
      "(630, 630)\n",
      "(201, 173, 3)\n",
      "(168, 300, 3)\n",
      "(183, 275, 3)\n",
      "(168, 300, 3)\n",
      "(197, 177, 3)\n",
      "(217, 232, 3)\n",
      "(231, 218, 3)\n",
      "(221, 228, 3)\n",
      "(200, 200, 3)\n",
      "(630, 630, 3)\n",
      "(259, 194, 3)\n",
      "(225, 225, 3)\n",
      "(243, 207, 3)\n",
      "(242, 208, 3)\n",
      "(214, 235, 3)\n",
      "(217, 232, 3)\n",
      "(252, 200, 3)\n",
      "(231, 218, 3)\n",
      "(251, 201, 3)\n",
      "(234, 215, 3)\n",
      "(225, 225, 3)\n",
      "(242, 208, 3)\n",
      "(252, 200, 3)\n",
      "(225, 225, 3)\n",
      "(213, 236, 3)\n",
      "(198, 150, 3)\n",
      "(225, 225, 3)\n",
      "(221, 228, 3)\n",
      "(225, 225, 3)\n",
      "(251, 201, 3)\n",
      "(225, 225, 3)\n",
      "(250, 201, 3)\n",
      "(225, 225, 3)\n",
      "(225, 225, 3)\n",
      "(168, 300, 3)\n",
      "(194, 259, 3)\n",
      "(442, 441, 3)\n",
      "(474, 356, 3)\n",
      "(530, 380, 3)\n",
      "(225, 225, 3)\n",
      "(630, 630)\n",
      "(225, 225, 3)\n",
      "(225, 225, 3)\n",
      "(222, 227, 3)\n",
      "(192, 192, 3)\n",
      "(417, 428, 3)\n",
      "(251, 201, 3)\n",
      "(201, 173, 3)\n",
      "(338, 276, 3)\n",
      "(614, 630, 3)\n",
      "(225, 225)\n",
      "(238, 212, 3)\n",
      "(393, 350, 3)\n",
      "(282, 230, 3)\n",
      "(248, 208, 3)\n",
      "(262, 227, 3)\n",
      "(1024, 1024)\n",
      "(326, 276, 3)\n",
      "(264, 210, 3)\n",
      "(275, 220)\n",
      "(250, 201, 3)\n",
      "(257, 196, 3)\n",
      "(225, 225, 3)\n",
      "(750, 750)\n",
      "(225, 225, 3)\n",
      "(217, 232, 3)\n",
      "(225, 225, 3)\n",
      "(275, 220)\n",
      "(442, 442)\n",
      "(236, 214, 3)\n",
      "(630, 630, 3)\n",
      "(361, 642, 3)\n",
      "(540, 504, 3)\n",
      "(1080, 1920, 3)\n",
      "(280, 420, 3)\n",
      "(442, 400, 3)\n",
      "(244, 206, 3)\n",
      "(225, 225, 3)\n",
      "(630, 630)\n",
      "(301, 275)\n",
      "(664, 550, 4)\n",
      "(442, 442, 3)\n",
      "(725, 728, 4)\n",
      "(442, 409)\n",
      "(512, 512, 4)\n",
      "(630, 630, 3)\n",
      "(537, 472, 3)\n",
      "(442, 442)\n",
      "(340, 339, 3)\n",
      "(400, 393, 4)\n",
      "(200, 300, 3)\n",
      "(400, 393, 4)\n",
      "(454, 442, 4)\n",
      "(680, 680, 3)\n",
      "(444, 468, 3)\n",
      "(442, 442)\n",
      "(449, 359, 3)\n",
      "[!] Negative files read!\n"
     ]
    }
   ],
   "source": [
    "img_yes = '../data/yes/'\n",
    "img_no = '../data/no/'\n",
    "\n",
    "yes_files = os.listdir(img_yes)\n",
    "no_files = os.listdir(img_no)\n",
    "\n",
    "yes_images, no_images = [], []\n",
    "print('[!] Reading files with positive diagnostic...')\n",
    "for file in yes_files:\n",
    "    yes_images.append(plt.imread(f'{img_yes}{file}'))\n",
    "print('[!] Positive files read!')\n",
    "\n",
    "print('[!] Reading files with negative diagnostic...')\n",
    "for file in no_files:\n",
    "    no_images.append(plt.imread(f'{img_no}{file}'))\n",
    "print('[!] Negative files read!')\n",
    "\n",
    "all_images = yes_images + no_images\n",
    "YES_SIZE, NO_SIZE = len(yes_images), len(no_images)\n",
    "TOTAL_SIZE = len(all_images)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez realizada la carga de las imágenes, comenzaremos el procesamiento de las mismas en diferentes etapas. Por una parte, debemos prestar atención a cómo la función ``imread`` realiza la lectura de las imágenes. Como se ha explicado previamente, esta función lee la imágen y la transforma en un *array* de tipo ``numpy``. Sin embargo, en función de la naturaleza de la imágen los *arrays* obtenidos pueden tener diferentes dimensiones o diferente tipo (``dtype``). En este caso, distinguimos tres tipos de imágen:\n",
    "\n",
    "1.- **Imágenes en escala de gris**: estas imágenes vienen representadas como arrays bidimensionales (matrices) cuyas dimensiones coinciden con las dimensiones de la imagen. Por ejemplo, si realizamos la carga de una imágen de 512x512 píxeles obtendremos una matriz de 512 filas y 512 columnas. Cada posición de este array será un número entero entre 0 y 255 que representa una tonalidad de gris. Este tipo de imágenes presenta la ventaja de que sus píxeles pueden representarse como enteros sin signo de 8 bits (``uint8`` en ``numpy``), por lo que disminuyen significativamente los requisitos de memoria.\n",
    "\n",
    "2.- **Imágenes en escala RGB**: estas imágenes vienen representadas como arrays tridimensionales. Una forma de entender estas imágenes sería como un conjunto de tres matrices, cada una representando un color, teniendo en cuenta además que cada matriz tiene las mismas dimensiones que la propia imágen. Por ejemplo, si se realiza la carga de una imágen RGB de 512x512 píxeles, obtendríamos un array de dimensiones ``(512, 512, 3)``. De nuevo, cada elemento de este array será un número entero entre 0 y 255, por lo que podrá representarse como un entero sin signo de 8 bits.\n",
    "\n",
    "3.- **Imágenes con formato ``.png``**: estas imágenes vienen representadas como arrays de cuatro dimensiones, es decir, son imágenes de tipo RGBA (las imágenes RGBA surgen de la combinación de imágenes RGB con un cuarto canal de tipo *alpha* que sirve para indicar el grado de opacidad de cada píxel). La principal diferencia con los formatos anteriores, es que cada elemento del *array* es un número real entre 0 y 1 y por tanto, se representan en memoria mediante números en coma flotante de 32 bits (``float32`` en ``numpy``).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESH = 30\n",
    "MAX_VALUE = 255\n",
    "\n",
    "def convert_to_int_matrix(img_list):\n",
    "    MIN, MAX = 0, 255\n",
    "    for i, img in enumerate(img_list):\n",
    "        if img.dtype == np.float32:\n",
    "            tmp = np.copy(img) * MAX\n",
    "            img_list[i] = tmp.astype(np.uint8)\n",
    "\n",
    "def resize_imgs(img_list, height, width):\n",
    "    for i, img in enumerate(img_list):\n",
    "        img_list[i] = cv2.resize(img, (height, width))\n",
    "\n",
    "def imgs_to_grayscale(img_list):\n",
    "    for i, img in enumerate(img_list):\n",
    "        if len(img.shape) == 3:\n",
    "            img_list[i] = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def gaussian_blur(img_list):\n",
    "    for i, img in enumerate(img_list):\n",
    "        img_list[i] = cv2.GaussianBlur(img, (5, 5), 0) \n",
    "\n",
    "def threshold_imgs(img_list):\n",
    "    for i, img in enumerate(img_list):\n",
    "        _, img_list[i] = cv2.threshold(img, THRESH, MAX_VALUE, cv2.THRESH_BINARY)\n",
    "\n",
    "def erode_imgs(img_list, iter=1):\n",
    "    for i, img in enumerate(img_list):\n",
    "        img_list[i] = cv2.erode(img, None, iterations=iter)\n",
    "\n",
    "def dilate_imgs(img_list, iter=1):\n",
    "    for i, img in enumerate(img_list):\n",
    "        img_list[i] = cv2.dilate(img, None, iterations=iter)\n",
    "\n",
    "def flatten_contour(contour_list):\n",
    "    tmp = contour_list[0]\n",
    "    shape = tmp.shape\n",
    "    aux = np.zeros(shape=(shape[0], shape[2]), dtype=int)\n",
    "    for i in range(shape[0]):\n",
    "        aux[i] = tmp[i].flatten()\n",
    "    return aux\n",
    "\n",
    "def find_extreme_points(contour_list):\n",
    "    col_1 = contour_list[:, 0]\n",
    "    col_0 = contour_list[:, 1]\n",
    "    x_left, x_right = np.argmin(col_0), np.argmax(col_0)\n",
    "    y_top, y_bot = np.argmax(col_1), np.argmin(col_1)\n",
    "    ret = np.zeros(shape=(4, 2), dtype=int)\n",
    "    ret[0, :], ret[1, :] = contour_list[x_left], contour_list[x_right]\n",
    "    ret[2, :], ret[3, :] = contour_list[y_top], contour_list[y_bot]\n",
    "    return ret  \n",
    "\n",
    "def get_contour(img_list_morph, img_list, mode):\n",
    "    extreme_points, i = [], 0\n",
    "    for img_morph, img in zip(img_list_morph, img_list):\n",
    "        cont, _ = cv2.findContours(image=img_morph, mode=mode, method=cv2.CHAIN_APPROX_NONE)\n",
    "        cont_flat = flatten_contour(cont)\n",
    "        extreme_points.append(find_extreme_points(cont_flat))\n",
    "        i+= 1\n",
    "        if i % 50 == 0: print(f'[!] {i} images processed...')\n",
    "        # print(extreme_points[-1])\n",
    "        img_copy = img.copy()\n",
    "        # print(f'img_shape: {img_copy.shape}')\n",
    "        # print(f'extreme_point: {extreme_points[-1]}')\n",
    "        # for i in range(4):\n",
    "        #     img_copy = cv2.circle(img_copy, extreme_points[-1][i, :], radius=5, color=(0, 255, 0), thickness=-1)\n",
    "        # cv2.imshow(\"Image\", img_copy)\n",
    "        # cv2.waitKey()\n",
    "        # cv2.drawContours(image=img_copy, contours=cont, contourIdx=-1, color=(0, 0, 255), thickness=4, lineType=cv2.LINE_AA)\n",
    "        # cv2.imshow(\"Image\", img_copy)\n",
    "        # cv2.waitKey()\n",
    "    print(f'[!] Total of {i} images processed!')\n",
    "    return np.array(extreme_points)  \n",
    "\n",
    "def draw_img(img_list, index):\n",
    "    if index < len(img_list):\n",
    "        cv2.imshow(\"Brain image\", img_list[index])\n",
    "        cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 240)\n",
      "(1080, 1920, 3)\n",
      "(664, 550, 4)\n",
      "(725, 728, 4)\n",
      "(512, 512, 4)\n",
      "(400, 393, 4)\n",
      "(400, 393, 4)\n",
      "(454, 442, 4)\n"
     ]
    }
   ],
   "source": [
    "INDEX = 0\n",
    "HEIGHT, WIDTH = 224, 224\n",
    "convert_to_int_matrix(all_images)\n",
    "all_images_morph = all_images.copy()\n",
    "draw_img(all_images_morph, INDEX)\n",
    "imgs_to_grayscale(all_images_morph)\n",
    "draw_img(all_images_morph, INDEX)  \n",
    "threshold_imgs(all_images_morph)\n",
    "draw_img(all_images_morph, INDEX)\n",
    "erode_imgs(all_images_morph, iter=2)\n",
    "draw_img(all_images_morph, INDEX)\n",
    "dilate_imgs(all_images_morph, iter=4)\n",
    "draw_img(all_images_morph, INDEX)\n",
    "gaussian_blur(all_images_morph)\n",
    "draw_img(all_images_morph, INDEX)\n",
    "cv2.destroyAllWindows()\n",
    "extreme_points = get_contour(all_images_morph, all_images, cv2.RETR_EXTERNAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_images(extreme_points, img_list):\n",
    "    new_images = []\n",
    "    for extreme_point, img in zip(extreme_points, img_list):\n",
    "        x_left, x_right = extreme_point[0, 1], extreme_point[1, 1]\n",
    "        y_top, y_bot = extreme_point[2, 0], extreme_point[3, 0]\n",
    "        size_h, size_v = x_right - x_left, y_top - y_bot\n",
    "        # print(f'img_shape: {img.shape}')\n",
    "        # print(f'x_left: {x_left} - x_right: {x_right} - y_top: {y_top} - y_bot: {y_bot}')\n",
    "        # tmp = np.zeros(shape=(size_h, size_v), dtype=np.uint8)\n",
    "        # tmp = img[x_left:x_right, y_bot:y_top].copy()\n",
    "        tmp = np.zeros(shape=(size_h, size_v), dtype=np.uint8)\n",
    "        for i, k in zip(range(x_left, x_right), range(size_h)):\n",
    "            for j, l in zip(range(y_bot, y_top), range(size_v)):\n",
    "                tmp[k, l] = img[i, j]\n",
    "        new_images.append(tmp)\n",
    "    return new_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grey_imgs = all_images.copy()\n",
    "imgs_to_grayscale(grey_imgs)\n",
    "new_images = cut_images(extreme_points, grey_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_images(img_morph_list, img_list):\n",
    "    correct_yes_images, correct_no_images = [], []\n",
    "    incorrect_yes_images, incorrect_no_images = [], []\n",
    "    for img_morph, img, i in zip(img_morph_list, img_list, range(len(img_list))):\n",
    "        cv2.imshow(\"Brain\", img_morph)\n",
    "        key = cv2.waitKey()\n",
    "        if key == 13:\n",
    "            if i < YES_SIZE:\n",
    "                correct_yes_images.append(img_morph)\n",
    "            else:\n",
    "                correct_no_images.append(img_morph)\n",
    "        elif key == 8:\n",
    "            if i < YES_SIZE:\n",
    "                incorrect_yes_images.append(img)\n",
    "            else:\n",
    "                incorrect_no_images.append(img)\n",
    "        if i % 50 == 0:\n",
    "            print(f'[!] {i} images checked...')\n",
    "    return correct_yes_images, correct_no_images, incorrect_yes_images, incorrect_no_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] 0 images checked...\n",
      "[!] 50 images checked...\n",
      "[!] 100 images checked...\n",
      "[!] 150 images checked...\n",
      "[!] 200 images checked...\n",
      "[!] 250 images checked...\n"
     ]
    }
   ],
   "source": [
    "correct_yes_images, correct_no_images, incorrect_yes_images, incorrect_no_images = check_images(new_images, grey_imgs)\n",
    "cv2.destroyAllWindows()\n",
    "resize_imgs(correct_yes_images, HEIGHT, WIDTH)\n",
    "resize_imgs(correct_no_images, HEIGHT, WIDTH)\n",
    "# correct_yes_images = np.load('./numpy_arrays/correct_yes_images.npy', allow_pickle=True)\n",
    "# correct_no_images = np.load('./numpy_arrays/correct_no_images.npy', allow_pickle=True)\n",
    "# incorrect_yes_images = np.load('./numpy_arrays/incorrect_yes_images.npy', allow_pickle=True)\n",
    "# incorrect_no_images = np.load('./numpy_arrays/incorrect_no_images.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] 203 correct images!\n",
      "[!] 50 incorrect images!\n"
     ]
    }
   ],
   "source": [
    "print(f'[!] {len(correct_yes_images) + len(correct_no_images)} correct images!')\n",
    "print(f'[!] {len(incorrect_yes_images) + len(incorrect_no_images)} incorrect images!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kmart\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    }
   ],
   "source": [
    "NP_PATH = './numpy_arrays'\n",
    "np.save(f'{NP_PATH}/correct_yes_images.npy', correct_yes_images, allow_pickle=True)\n",
    "np.save(f'{NP_PATH}/correct_no_images.npy', correct_no_images, allow_pickle=True)\n",
    "np.save(f'{NP_PATH}/incorrect_yes_images.npy', incorrect_yes_images, allow_pickle=True)\n",
    "np.save(f'{NP_PATH}/incorrect_no_images.npy', incorrect_no_images, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:180: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] 50 images processed...\n",
      "[!] Total of 50 images processed!\n",
      "[!] 0 images checked...\n",
      "[!] 17 correct images!\n",
      "[!] 33 incorrect images!\n"
     ]
    }
   ],
   "source": [
    "THRESH, INDEX = 20, 0\n",
    "YES_SIZE, NO_SIZE = len(incorrect_yes_images), len(incorrect_no_images)\n",
    "\n",
    "original_incorrect_images = np.concatenate((incorrect_yes_images, incorrect_no_images))\n",
    "all_incorrect_images = original_incorrect_images.copy()\n",
    "\n",
    "threshold_imgs(all_incorrect_images)\n",
    "erode_imgs(all_incorrect_images, iter=2)\n",
    "dilate_imgs(all_incorrect_images, iter=4)\n",
    "gaussian_blur(all_incorrect_images)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "extreme_points = get_contour(all_incorrect_images, original_incorrect_images, cv2.RETR_EXTERNAL)\n",
    "new_images = cut_images(extreme_points, original_incorrect_images)\n",
    "res_imgs = check_images(new_images, original_incorrect_images)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f'[!] {len(res_imgs[0]) + len(res_imgs[1])} correct images!')\n",
    "print(f'[!] {len(res_imgs[2]) + len(res_imgs[3])} incorrect images!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] 220 total correct images!\n",
      "[!] 33 total incorrect images!\n"
     ]
    }
   ],
   "source": [
    "resize_imgs(res_imgs[0], HEIGHT, WIDTH)\n",
    "resize_imgs(res_imgs[1], HEIGHT, WIDTH)\n",
    "res_correct_yes = np.concatenate((np.load(f'{NP_PATH}/correct_yes_images.npy'), np.array(res_imgs[0], dtype=np.uint8)))\n",
    "res_correct_no = np.concatenate((np.load(f'{NP_PATH}/correct_no_images.npy'), np.array(res_imgs[1], dtype=np.uint8)))\n",
    "print(f'[!] {len(res_correct_yes) + len(res_correct_no)} total correct images!')\n",
    "print(f'[!] {TOTAL_SIZE - (len(res_correct_yes)+len(res_correct_no))} total incorrect images!')\n",
    "np.save(f'{NP_PATH}/correct_yes_images_2.npy', res_correct_yes, allow_pickle=True)\n",
    "np.save(f'{NP_PATH}/correct_no_images_2.npy', res_correct_no, allow_pickle=True)\n",
    "np.save(f'{NP_PATH}/incorrect_yes_images_2.npy', res_imgs[2], allow_pickle=True)\n",
    "np.save(f'{NP_PATH}/incorrect_no_images_2.npy', res_imgs[3], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_yes = np.ones(shape=(len(res_correct_yes),), dtype=np.uint8)\n",
    "class_no = np.zeros(shape=(len(res_correct_no),), dtype=np.uint8)\n",
    "np.save(f'{NP_PATH}/classes.npy', np.concatenate((class_yes, class_no)), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134\n",
      "86\n"
     ]
    }
   ],
   "source": [
    "print(len(res_correct_yes))\n",
    "print(len(res_correct_no))\n",
    "for img in res_correct_yes:\n",
    "    cv2.imshow(\"yes\", img)\n",
    "    cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "for img in res_correct_no:\n",
    "    cv2.imshow(\"no\", img)\n",
    "    cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12749f567798517b8543354a13719bbd42e9e3e56a89ba27a040f4f72d5c2230"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
