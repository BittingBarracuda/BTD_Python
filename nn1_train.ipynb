{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import joblib\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data'\n",
    "def load_dataset():\n",
    "    X_yes = np.load(f'{DATA_PATH}/def_yes_images.npy')\n",
    "    X_no = np.load(f'{DATA_PATH}/def_no_images.npy')\n",
    "    classes = np.load(f'{DATA_PATH}/classes.npy')\n",
    "\n",
    "    print(f'X_yes shape: {X_yes.shape}')\n",
    "    print(f'X_no shape {X_no.shape}')\n",
    "    print(f'classes shape: {classes.shape}')\n",
    "\n",
    "    return X_yes, X_no, classes\n",
    "\n",
    "def reshape_dataset(X_yes, X_no):\n",
    "    X = np.row_stack((X_yes, X_no))\n",
    "    N, SIZE_H, SIZE_V = X.shape\n",
    "    X = np.reshape(X, newshape=(N, SIZE_H * SIZE_V))\n",
    "    print(f'X shape: {X.shape}')\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_yes shape: (135, 214, 214)\n",
      "X_no shape (87, 214, 214)\n",
      "classes shape: (222,)\n",
      "X shape: (222, 45796)\n"
     ]
    }
   ],
   "source": [
    "X_yes, X_no, classes = load_dataset()\n",
    "X = reshape_dataset(X_yes, X_no)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptr贸n multi-capa con reducci贸n de dimensionalidad PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_pca_variance(n_components, variance_cumsum):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 10))\n",
    "    ax.set_xlabel('Componente principal')\n",
    "    ax.set_ylabel('Porcentaje de varianza acumulada')\n",
    "    ax.plot(\n",
    "        np.arange(1, n_components + 1),\n",
    "        variance_cumsum,\n",
    "    )\n",
    "    i, aux = 0, 0\n",
    "    for x, y in zip(np.arange(1, n_components + 1, 25), variance_cumsum[:-1:25]):\n",
    "        ax.plot(x, y, 'ko')\n",
    "        ax.annotate(\n",
    "            np.round(y, 3),\n",
    "            (x, y),\n",
    "            textcoords='offset points',\n",
    "            xytext=(-7, 12),\n",
    "            ha='center'\n",
    "        )\n",
    "    plt.show()\n",
    "\n",
    "def get_pca(X):\n",
    "    pca = PCA(n_components=None)\n",
    "    X_tmp = pca.fit_transform(X)\n",
    "    n_components = pca.n_components_\n",
    "    variance_cumsum = pca.explained_variance_ratio_.cumsum()\n",
    "    print(f'X_tmp shape: {X_tmp.shape}')\n",
    "    print(f'N_components: {n_components}')\n",
    "    print(f'Porcentaje de varianza acumulada: {variance_cumsum}')\n",
    "    draw_pca_variance(n_components, variance_cumsum)\n",
    "    return pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pca(X)\n",
    "sd = seed(time())\n",
    "\n",
    "pipe_1 = Pipeline([\n",
    "    ('Scaler', StandardScaler()),\n",
    "    ('PCA', PCA(n_components=None)),\n",
    "    ('MLPClassifier', MLPClassifier(random_state=sd))\n",
    "])\n",
    "\n",
    "RSKFold_1 = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=sd)\n",
    "hidden_layers_1 = [(100, 50, 25), (200, 100, 50), (150, 75, 30, 10), (200, 100, 50, 25)]\n",
    "\n",
    "grid_space_1 = [\n",
    "    {\n",
    "        'MLPClassifier__solver': ['lbfgs', 'adam'],\n",
    "        'MLPClassifier__max_iter': range(1000, 3500, 500),\n",
    "        'MLPClassifier__activation': ['logistic', 'tanh', 'relu'],\n",
    "        'MLPClassifier__hidden_layer_sizes': hidden_layers_1,\n",
    "        'MLPClassifier__learning_rate_init': [1e-4, 1e-3, 1e-2, 1e-1]\n",
    "    }, \n",
    "    {\n",
    "        'MLPClassifier__solver': ['sgd'],\n",
    "        'MLPClassifier__max_iter': range(1000, 3500, 500),\n",
    "        'MLPClassifier__activation': ['logistic', 'tanh', 'relu'],\n",
    "        'MLPClassifier__hidden_layer_sizes': hidden_layers_1,\n",
    "        'MLPClassifier__learning_rate_init': [1e-4, 1e-3, 1e-2, 1e-1],\n",
    "        'MLPClassifier__momentum': np.arange(0.1, 1, 0.1)\n",
    "    }\n",
    "]\n",
    "\n",
    "grid_1 = GridSearchCV(\n",
    "    estimator=pipe_1,\n",
    "    param_grid=grid_space_1,\n",
    "    cv=RSKFold_1,\n",
    "    scoring='balanced_accuracy',\n",
    "    return_train_score=True,\n",
    "    verbose=4,\n",
    "    n_jobs=-1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_1 = grid_1.fit(X, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RES_FILE_NAME_1 = 'nn_1_results.pkl'\n",
    "joblib.dump(res_1, RES_FILE_NAME_1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptr贸n multi-capa con reducci贸n de dimensionalidad PCA y *data augmentation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(imgs, classes, aug_per_image, imgs_trans):\n",
    "    new_images, new_classes = [], []\n",
    "    for img, y, i in zip(imgs, classes, range(1, len(imgs) + 1)):\n",
    "        for _ in range(aug_per_image):\n",
    "            tmp_img = imgs_trans(image=img)[\"image\"]\n",
    "            new_images.append(tmp_img)\n",
    "            new_classes.append(y)\n",
    "        if i % 50 == 0: print(f'[!] {i} images agumented...')\n",
    "    print(f'[!] Total of {len(imgs)} images augmented!\\n')\n",
    "    return new_images, new_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_yes shape: (135, 214, 214)\n",
      "X_no shape (87, 214, 214)\n",
      "classes shape: (222,)\n"
     ]
    }
   ],
   "source": [
    "X_yes, X_no, classes = load_dataset()\n",
    "#X = reshape_dataset(X_yes, X_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] 50 images agumented...\n",
      "[!] 100 images agumented...\n",
      "[!] Total of 135 images augmented!\n",
      "\n",
      "[!] 50 images agumented...\n",
      "[!] Total of 87 images augmented!\n",
      "\n",
      "X shape: (4440, 45796)\n"
     ]
    }
   ],
   "source": [
    "imgs_trans = A.Compose([\n",
    "    A.HorizontalFlip(p=0.25),\n",
    "    A.VerticalFlip(p=0.25),\n",
    "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), p=0.25),\n",
    "    A.Rotate(limit=[-15, 15], p=0.25, border_mode=cv2.BORDER_CONSTANT),\n",
    "    A.Affine(translate_percent=(-0.05, 0.05))\n",
    "])\n",
    "\n",
    "X_yes_aug = data_augmentation(X_yes, 20, imgs_trans)\n",
    "X_no_aug = data_augmentation(X_no, 20, imgs_trans)\n",
    "X = reshape_dataset(X_yes_aug, X_no_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_images(imgs):\n",
    "    for img in imgs:\n",
    "        cv2.imshow(\"Img\", img)\n",
    "        cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "# draw_images(X_yes_aug)\n",
    "# draw_images(X_no_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = seed(time())\n",
    "\n",
    "pipe_2 = Pipeline([\n",
    "    ('Scaler', StandardScaler()),\n",
    "    ('PCA', PCA(n_components=None)),\n",
    "    ('MLPClassifier', MLPClassifier(random_state=sd))\n",
    "])\n",
    "\n",
    "RSKFold_2 = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=sd)\n",
    "hidden_layers_2 = [(100, 50, 25), (200, 100, 50), (150, 75, 30, 10), (200, 100, 50, 25)]\n",
    "\n",
    "grid_space_2 = [\n",
    "    {\n",
    "        'MLPClassifier__solver': ['lbfgs', 'adam'],\n",
    "        'MLPClassifier__max_iter': range(1000, 3500, 500),\n",
    "        'MLPClassifier__activation': ['logistic', 'tanh', 'relu'],\n",
    "        'MLPClassifier__hidden_layer_sizes': hidden_layers_2,\n",
    "        'MLPClassifier__learning_rate_init': [1e-4, 1e-3, 1e-2, 1e-1]\n",
    "    }, \n",
    "    {\n",
    "        'MLPClassifier__solver': ['sgd'],\n",
    "        'MLPClassifier__max_iter': range(1000, 3500, 500),\n",
    "        'MLPClassifier__activation': ['logistic', 'tanh', 'relu'],\n",
    "        'MLPClassifier__hidden_layer_sizes': hidden_layers_2,\n",
    "        'MLPClassifier__learning_rate_init': [1e-4, 1e-3, 1e-2, 1e-1],\n",
    "        'MLPClassifier__momentum': np.arange(0.1, 1, 0.1)\n",
    "    }\n",
    "]\n",
    "\n",
    "grid_2 = GridSearchCV(\n",
    "    estimator=pipe_2,\n",
    "    param_grid=grid_space_2,\n",
    "    cv=RSKFold_2,\n",
    "    scoring='balanced_accuracy',\n",
    "    return_train_score=True,\n",
    "    verbose=4,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_2 = grid_2.fit(X, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RES_FILE_NAME_2 = 'nn_2_results.pkl'\n",
    "joblib.dump(res_2, RES_FILE_NAME_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12749f567798517b8543354a13719bbd42e9e3e56a89ba27a040f4f72d5c2230"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
